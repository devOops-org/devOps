# 엘라스틱 서치 실무 가이드

## 검색 시스템 이해하기
- 전체 흐름
    - 검색엔진으로서 엘라스틱 서치의 이해
    - 데이터의 모델링
    - 데이터의 검색 방법과 효율성 제고
    - 데이터를 그룹화하고 통계치를 얻는 집계
    - 엘라스틱 서치의 기반 기술인 루씬
    - 안정된 클러스터 운영

### 1.1 검색시스템의 이해
검색 시스템과 검색엔진의 정의, 검색엔진인 엘라스틱 서치와 데이터베이스의 차이

> 검색 시스템이란?
- 검색엔진이란 광활한 웹에서 정보를 수집해 검색 결과를 제공하는 프로그램
- 검색시스템은 대용량 데이터를 기반으로 신회성있는 검색결과를 제공하기 위해 검색엔진을 기반으로 구축된 시스템을 통칭하는 용어
    - 수집기를 이용한 데이터 수집, 다수의 검색엔진을 이용한 색인, 검색 결과를 UI로 제공
    - 시스템 내부의 정책에 따라 특정 필드나 문서에 가중치를 둔 검색 정확도

> 검색 시스템의 구성 요소

- 정보를 수집하는 수집기
- 수집한 데이터를 저장하는 스토리지
- 수집한 데이터를 검색에 적절한 형태로 변환하는 색인기
- 색인된 데이터에서 일치하는 문서를 찾는 검색기

- 수집기
    - 파일, 데이터베이스, 웹페이지 등 웹 상의 대부분의 정보가 수집대상이다.
    - 파일의 경우 수집기가 파일명, 파일 내용, 파일 경로 등의 정보를 수집하여 저장하면 검색엔진이 저장된 정보를 검색하여 질의에 응답하게 된다.
- 스토리지
    - 데이터베이스에서 데이터를 저장하는 물리적인 저장소
- 색인기
    - 수집된 데이터를 검색 가능한 구조로 가공하고 저장
    - 다양한 형태소 분석기를 조합해 정보에서 의미가 있는 용어를 추출, 검색에 유리한 역색인 구조로 데이터를 저장
- 검색기
    - 사용자의 질의를 입력받아 색인기에서 저장한 역색인 구조에서 일치하는 문서를 찾아 결과로 반환
    - 질의와 문서가 일치하는지는 유사도 기반의 검색 순위 알고리즘으로 판단
    - 검색기 또한 색인기와 마찬가지로 형태소 분석기를 이용해 사용자 질의에서 유의미한 용어를 추출해 검색
        - 사용하는 형태소 분석기에 따라 검색 품질 차이가 발생할 수 있다.

> 관계형 데이터베이스와의 차이점
- 관계형 데이터베이스의 특징
    - 데이터를 통합 관리하는 데이터의 집합
    - 저장 방식에 따라 크게 관계형 또는 계층형 데이터베이스로 구분
    - 모든 데이터베이스는 중복을 제거하고, 정형 데이터로 구조화해 행과 열로 구성된 테이블에 저장
    - SQL 문을 이용해 원하는 정보의 검색이 가능하나 텍스트 매칭을 통한 단순한 검색만 가능
    - 텍스트를 여러 단어로 변형하거나 여러 개의 동의어나 유의어를 활용한 검색은 불가능
- 검색엔진의 특징
    - 비정형 데이터를 색인하고 검색
    - 형태소 분석을 통해 사람이 구사하는 자연어의 처리가 가능
    - 역색인 구조를 바탕으로 빠른 검색 속도를 보장

- 용어 구분

    |엘라스틱서치|관계형 데이터베이스|
    |:---:|:---:|
    |인덱스(Index)|데이터베이스(Database)|
    |샤드(shard)|파티션(partition)|
    |타입(type)|테이블(table)|
    |문서(document)|행(row)|
    |필드(field)|열(column)|
    |매핑(mapping)|스키마(schema)|
    |Query DSL|SQL|
    
    ```text
    * 관계형데이터베이스의 인덱스는 where 절의 쿼리와 join을 빠르게 만드는 보조 데이터 도구로 사용
    * 6.0 이하 버전 하나의 인덱스 내부에 기능에 따라 데이터를 분류하고 여러 개의 타입을 만들어 사용
    * 현재는 하나의 인덱스에 하나의 타입만 구성하도록 변경
    ```

- 요청 방식 차이 

    |기능|엘라스틱서치|데이터베이스|
    |:----:|:----:|:----:|
    |데이터의 조회|GET|SELECT|
    |데이터의 생성|PUT|INSERT|
    |인덱스 업데이트, 데이터 조회|POST|UPDATE, SELECT|
    |데이터 삭제|DELETE|DELETE|
    |인덱스의 정보 확인|HEAD|-|

    ```text
    * RESTful API
    HTTP 헤더(header)와 URL만 사용해 다양한 형태의 요청을 할 수 있는 HTTP 프로토콜을 최대한 활용하도록 고안된 아키텍처
    ```

    - 엘라스틱 서치를 사용하기 위한 간단한 API 요청 구조
    
    ```shell
    curl -X(method) http://host:port/(index)/(type)/(document id) -d '{json data}'
    ```

> 엘라스틱 서치의 API의 기본 문법
    

### 1.2. 검색 시스템과 엘라스틱서치

> 엘라스틱 서치가 강력한 이유
- 오픈소스 검색엔진
- 전문 검색
- 통계 분석
- 스키마리스
- RESTful API
- 멀티테넌시(Multi-tenancy)
- Document-Oriented
- 역색인(Inverted Index)
- 확장성과 가용성

> 엘라스틱 서치의 약점
- '실시간'이 아닌점
- 트랜잭션과 롤백 기능을 제공하지 않는다.
- 데이터의 업데이트를 제공하지 않는다.
    

### 1.3 실습 환경 구축
> 엘라스틱 서치 설치
- 자바 설치
- 엘라스틱 서치 설치시 사용자 계정을 생성후 설치 권장
    ```json
    {
      "name": "b93c3535b922",
      "cluster_name": "docker-cluster",
      "cluster_uuid": "2Ql712GMTNyQBaVy0Upz9A",
      "version": {
        "number": "7.9.3",
        "build_flavor": "default",
        "build_type": "docker",
        "build_hash": "c4138e51121ef06a6404866cddc601906fe5c868",
        "build_date": "2020-10-16T10:36:16.141335Z",
        "build_snapshot": false,
        "lucene_version": "8.6.2",
        "minimum_wire_compatibility_version": "6.8.0",
        "minimum_index_compatibility_version": "6.0.0-beta1"
      },
      "tagline": "You Know, for Search"
    }
    ```

- 주요 설정 항목

    |속성명|설명|
    |:---|:---|
    |`cluster.name`|클러스터로 여러 노드를 하나로 묶기 위해 클러스터 명을 등록|
    |`node.master`|마스터 노드로 동작 여부를 지정|
    |`node.data`|데이터 노드로 동작 여부를 지정|
    |`node.name`|엘라스틱 서치 노드명을 설정, 미설정시 임의값을 설정|
    |`path.data`|엘라스틱 서치의 인덱스 경로를 지정, 미설정시 data 디렉토리에 인덱스 생성|
    |`path.logs`|엘라스틱 서치의 노드와 클러스터에서 생성되는 로그를 저장할 경로를 지정, 기본 경로는 `/path/to/logs`|
    |`path.repo`|엘라스틱서치 인덱스를 백업하기 위한 스냅샷의 경로를 지정|
    |`network.hosts`|특정 IP만 엘라스틱서치에 접근하도록 허용, 모든 IP 허용시 `0.0.0.0`, IP 값으로 `127.0.0.1`을 설정 시 개발 모드에서 프로덕트 모드로 자동 변경|
    |`http.port`|엘라스틱 서치 서버에 접근할 수 있는 HTTP API 호출을 위한 포트 번호 지정, 기본값은 `9200`|
    |`transport.tcp.port`|엘라스틱서치 클라이언트가 접근할 수 있는 TCP 포트, 기본값은 `9300`|
    |`discovery.zen.ping.unicast.hosts`|노트가 여러개인 경우 유니캐스트로 활성화된 다른 서버를 찾는다. 클러스터로 묶인 노드(서버)의 IP를 지정하면된다.|
    |`discovery.zen.minimum_master_nodes`|마스터 노드의 선출 기준이 되는 노드의 수를 지정|

> 키바나 설치
- 데이터 시각화 프로그램
- 엘라스틱 서치에 색인된 데이터를 검색하거나, 문서를 추가한다거나 삭제하는 등의 기능을 손쉽게 구현할 수 있다.
- Dev Tools 메뉴에서 문서와 매핑의 추가, 삭제 등의 작업을 JSON 포맷으로 엘라스틱서치에 요청할 수 있다.
- Kibana > Dev Tools > curl 요청 구조
    ```text
    GET _search
    {
        "query": {
            "match_all": {}
        }
    }
    ```
- `GET`: 요청 전달 방식 중 하나로 어떠한 변경 없이 쿼리에 대한 결과를 반환 받는 용도
- `_search`: 검색 쿼리를 의미, `_search` 앞 부분에 인덱스를 명시하여 해당 인덱스로만 범위를 한정해서 검색을 수행할 수도 있다.
    - 여기서는 어떠한 인덱스도 지정하지 않았기 때문에 전체 인덱스를 대상으로 검색이 수행된다.
    - size가 기본값 01으로 설정되어 있기 때문에 검색 결과로 10개의 문서만 반환하기 때문에 많은 양의 문서가 색인되어 있더라도 결과가 빠르게 반환된다.
    - curl 명령어에서는 -X 옵션 다음으로 지정했던 도메인 부분에 해당한다.
    - 키바나를 통해 전달되는 쿼리는 무조건 설정에 지정된 엘라스틱 서치로 전달되기 때문에 생략가능
  
- `{...}`: 쿼리 본문에 해당하며 모든 문서를 검색, curl 명령어에서는 -d 옵션에 해당

### 2 엘라스틱 서치 살펴보기

> 엘라스틱 서치를 구성하는 개념

분산 시스템을 지향하는 엘라스틱 서치의 전체적인 아키텍처에 대한 이해

- 기본 용어
    - 인덱스, 타입 문서, 필드로 구성
    - @인덱스
        - 데이터 저장 공간
        - 하나의 인덱스는 하나의 타입을 가지며, 하나의 물리적인 노드에 여러 개의 논리적인 인덱스를 생성할 수 있다.
        - 검색 시 인덱스 이름으로 문서를 검색, 여러 인덱스를 동시에 검색하는 것도 가능
        - 엘라스틱 서치를 분산환경으로 구성하는 경우, 하나의 인덱스가 여러 노드에 분산되어 저장되어 관리가 된다.
        - 엘라스틱 서치는 인덱스 생성 시 기본적으로 5개의 프라이머리 샤드와 1개의 레플리카 샤드 세트를 생성한다.
        - 인덱스 이름은 모두 소문자여야 하며 추가, 수정, 삭제, 검색은 RESTful API로 수행이 가능하다.
        - `만약 인덱스가 없는 상태에서 데이터가 추가된다면 데이터를 이용해 인덱스가 자동으로 생성된다.`
    - @샤드
        - 색인된 문서는 하나의 인덱스에 담긴다. 인덱스 내부에 색인된 데이터는 물리적인 공간에 여러 개의 파티션으로 나뉘어 구성되는데, 이 파티션을 엘라스틱 서치에서는 샤드라 부른다.
        - 엘라스틱 서치는 다수의 샤드로 문서를 분산 저장하고 있어 데이터 손실 위험을 최소화할 수 있다.
    - @타입
        - 타입(Type)은 인덱스의 논리적 구조를 의마하며, 인덱스 속성에 따라 분류하기도 한다.
        - 6.1 버전 부터는 인덱스당 하나의 타입만을 사용할 수 있다.
    - @문서
        - 문서는 엘라스틱 서치에서 데이터가 저장되는 최소 단위이다.
        - 기본적으로 JSON 포맷으로 데이터가 저장된다.
        - 데이터베이스와 비교하자면 테이블의 행이 엘라스틱 서치의 문서에 해당한다고 볼 수 있다.
        - 하나의 문서는 다수의 필드로 구성돼 있는데 각 필드는 데이터의 형태에 따라 용도에 맞는 데이터 타입(Data Type)을 정의해야 한다.
        - 또한 문서는 중첩 구조를 지원하기 때문에 이를 이용해 문서 안에 문서를 지정하는 것도 가능하다.
    - @필드
        - 필드는 문서를 구성하기 위한 속성
        - 일반적으로 데이터베이스의 컬럼과 비교할 수 있으나, 컬럼이 정적인 데이터 탕비인데 반해 필드는 좀 더 동적인 데이터 타입이라 할 수 있다.
        - 하나의 필드는 목적에 따라 다수의 데이터 타입을 가질 수 있다. 
          ex) 매칭 검색, 초성 검색을 지원할 수 있도록 2개의 데이터 타입을 정의하는 것이 가능
    - @매핑
        - 문서의 필드와 필드의 속성을 정의, 그에 따른 색인 방버븡 정의하는 프로세스
        - 인덱스의 매핑 정보에는 여러 가지 데이터 타입을 지정할 수 있지만 필드명은 중복해서 사용할 수 없다.

- 노드의 종류
    - @클러스터는 물리적인 노드 인스턴스들의 모임이라 할 수 있다.
    - 클러스터는 모든 노드의 검색과 색인 작업을 관장하는 논리적인 개념이라 할 수 있다.
    - 관계형 데이터베이스의 경우 모든 요청을 서버 하나에서 처리하여 결과를 제공하지만 엘라스틱 서치의 경우에는 다수의 서버로 분산해서 처리하는 것이 가능하여 대용량 데이터를 처리할 수 있다.
    - 분산 처리를 위해서는 다양한 형태의 노드들을 조합하여 클러스터를 구성해야 한다.
    - 기본적으로 마스터 노드가 전체적인 클러스터를 관리하고 데이터 노드가 실제 데이터를 관리한다.
    - 4가지 유형의 노드

        |노드명|용도|
        |:---|:---|
        |마스터노드(Master Node)|- 클러스터를 관리 <br/>- 노드 추가와 제거 같은 클러스터의 전반적인 관리를 담당한다.|
        |데이터 노드(Data Node)|- 실질적인 데이터를 저장한다. <br/>- 검색과 통계 같은 데이터 관련 작업을 수행한다.|
        |코디네이팅 노드(Coordinating Node)|- 사용자의 요청만 받아서 처리 <br/>- 클러스터 관련 요청은 마스터 노드에 전달하고 데이터 관련 요청은 데이터 노드에 전달한다.|
        |인제스트 노드(Ingest Node)|- 문서의 전처리 작업을 담당한다. <br/> - 인덱스 생성 전 문서의 형식을 다양하게 변경할 수 있다.|
        
        - 설정에 따라 각 노드는 한 가지 유형으로 동작할 수도 있고 여러 개의 유형을 겸해서 동작할 수 있다.
    
    - 마스터 노드(Master Node)
        - 인덱스를 생성, 삭제하는 등 클러스터와 관련된 전반적인 작업을 담당한다.
        - 위와 같은 역할을 수행하기 위해서 네트워크 속도가 빠르고 지연이 없는 노드를 마스터 노드로 선정해야 한다.
        - 다수의 노드를 마스터 노드로 성정할 수 있지만 결과적으로 하나의 노드만이 마스터 노드로 선출되어 동작한다.
        - 마스터 노드 전용으로 설정하는 방법
            - `conf/elasticsearch.yml`
            ```yaml
            node.master: true
            node.data: false
            node.ingest: false
            search.remote.connect: false
            ```
    - 데이터 노드(Data Node)
        - 데이터 노드는 문서가 실제로 저장되는 노드
        - 데이터가 실제로 분산 저장되는 물리적 공간인 샤드가 배치되는 노드
        - 색인 작업은 CPU, 메모리, 스토리지 같은 컴퓨팅 리소스를 많이 소모하기 때문에 리소스 모니터링을 필요로한다.
        - 데이터 노드는 가능한 마스터 노드와 분리해서 구성하는 것이 좋다.
        - 단 색인할 문서의 수가 적으면 함께 구성해도 상관은 없다.
        - 데이터 노드로 성정하는 방법
            - `conf/elasticsearch.yml`
            ```yaml
            node.master: false
            node.data: true
            node.ingest: false
            search.remote.connect: false
            ```
    - 코디네이팅 노드(Coordinating Node)
        - 데이터 노드, 마스터 노드, 인제스트 노드의 역할을 하지 않고, 들어온 요청을 단순히 라운드로빈 방식으로 분산시켜 주는 노드이다.
        - 코디네이팅 노드로 설정하는 방법
            - `conf/elasticsearch.yml`
            ```yaml
            node.master: false
            node.data: false
            node.ingest: false
            search.remote.connect: false
            ```
    - 인제스트 노드(Ingest Node)
        - 색인 전 데이터를 전처리 하기 위한 노드
        - 데이터의 포맷을 변경하기 위해 스크립트로 전처리 파이프라인을 구성하고 실행할 수 있다.
            - `conf/elasticsearch.yml`
            ```yaml
            node.master: false
            node.data: false
            node.ingest: true
            search.remote.connect: false
            ```

- 클러스터, 노드, 샤드
    - 클러스터와 노드의 관계 (하나의 클러스터에 노드1, 노드2로 구성되는 경우)
        - 엘라스틱 서치 클러스터는 인덱스의 문서를 조회할 때 마스터 노드를 통해 2개의 노드를 모두 조회하여 각 데이터를 취합한 후 결과를 하나로 합쳐 제공한다.
        - 현재는 하나의 클러스터로만 구성되어 있지만 여러 개의 클러스터를 연결하여 구성할 수도 있다.
            - 두 개 이상의 클러스터로 구성하는 경우 각 클러스터 명으로 구분되며 명시하지 않는 경우 임의 문자열로 지정된다.
        - `클러스터에 있는 노드는 실시간으로 추가, 제거가 가능하여 가용성, 확장성 측면에서 매우 유연하다.`
    - 클러스터의 동작 방식 이해 (하나의 클러스터에 3개의 노드로 구성되는 경우)
        - 프라미머리 샤드와 레플리카 샤드의 수를 조정하며 인덱스 생성 시 클러스터가 어떻게 동작하는지 분석
        - 프라이머리 샤드 3개, 레플리카 샤드 0개를 세트로 구성하는 경우
            ```json
            {
              "settings": {
                "index": {
                  "number_of_shards": 3,
                  "number_of_replicas": 0
                }
              }
            }
            ```
            - 샤드는 분산된 데이터에 따라 순차적인 번호를 가진다.
            - 일반적으로 프라이머리 샤드느 안정성을 위해 하나의 노드에 하나씩 분산된다.
            - 인덱스에 다수의 문서를 색인하게 되면 문서는 3개의 샤드 골고루 분산 저장한다.
              
        - 프라이머리 샤드 6개, 레플리카 샤드 0개를 세트로 구성하는 경우
            ```json
            {
              "settings": {
                "index": {
                  "number_of_shards": 6,
                  "number_of_replicas": 0
                }
              }
            }
            ```
            - 3개의 노드에 프라이머리 샤드 6개가 노드당 2개가 배치되며, 색인 시 6개의 샤드에 데이터가 분산된다.

        - 프라이머리 샤드 3개, 레플리카 샤드 1개 세트 구성
            - 레플리카 샤드는 프라이머리 샤드의 복제본이다.
            ```json
            {
              "settings": {
                "index": {
                  "number_of_shards": 3,
                  "number_of_replicas": 1
                }
              }
            }
            ```
            - 엘라스틱 서치는 장애 시 레플리카 샤드를 이용해 샤드를 복구한다.
            - 프라이머리 샤드와 레플리카 샤드가 서로 다른 노드에 배치된다.

        - 프라이머리 샤드 3개, 레플리카 샤드 3개 세트 구성
            - 레플리카 샤드는 프라이머리 샤드의 복제본이다.
            ```json
            {
              "settings": {
                "index": {
                  "number_of_shards": 3,
                  "number_of_replicas": 3
                }
              }
            }
            ```
            - 프라이머리 샤드의 복제본이 존재하기 때문에 물리적인 노드 하나가 죽더라도 나머지 노드 2개가 전체 데이터를 복구할 수 있다.
            - 장애가 발생하면 마스터 노트드는 데이터를 재분배하거나 레플리카 샤드를 프라이이머리 샤드로 승격시켜 서비스 중단 없는 복구가 가능해진다.
        - `장애극복(Failover) 상황을 염두에 두고 노드와 샤드의 수를 적절하게 구성해야 한다.`

> 엘라스틱서치에서 제공하는 주요 API
- 문서를 색인하기 위해서는 기본적으로 인덱스를 생성해야 한다.
- 인덱스를 통해 입력되는 문서의 필드를 정의하고, 각 필드에 알맞은 데이터 타입을 지정해야 한다.
- index vs indices
    - index: 색인된 데이터
    - indexing: 색인하는 과정
    - indices: 매핑 정보를 저장하는 논리적인 데이터 공간

- 스키마리스
    - 문서를 색인하기 위해서는 기본적으로 인덱스를 생성하는 과정이 필요한데, 인덱스를 생성하는 과정 없이 문서를 추가하더라도 문서가 색인되도록 지원하는 기능
    - 최초 문서가 색인될 때 인덱스의 존재여부를 확인하고 인덱스가 존재하지 않는다면 문서를 분석해서 문서가 색인될 수 있도록 인덱스를 자동 생성하는 기능
    - 이는 성능과 밀접한 연관이 있기 때문에 특수한 상황 및 데이터 구조와 검색방식을 확실히 이해하고 사용해야 한다.
    - 인덱스를 자동 생성하는 경우 특정 단어를 검색할 때 검색 결과에서 누락되는 등 문제가 발생할 가능성이 높다.
    - 기본적으로 모든 필드가 text 타입과 keyword 타입을 동시에 제공하는 멀티필드 기능으로 구성된다.
    - 모든 필드가 text 타입 필드와 keyword 타입 필드를 동시에 필요로 하지않으므로 공간의 낭비를 초래한다.
    - 이 경우 검색 품질이 떨어지거나 성능상 문제가 발생할 가능성이 커진다.
    - 스키마리스를 이용해 색인한다면 기본적으로 text 타입의 Standard Analyzer를 사용하는 데이터 타입이 정의된다.
        - 이 경우 분석기가 문자열을 토큰으로 분리하여 Term이 생성되고 검색시 정확하게 matching 되는 키워드만 검색하게 될 것이다.
        - 원하는 결과를 얻기 위해서는 한글 형태소를 분석하는 분석기를 사용하도록 데이터 타입을 직접 정의해야 한다.
    - 스키마리스 사용 중지 방법
        - 노드 설정 파일 수정
        - 자동 인덱스 생성 기능 비활성화
        ```yaml
        action.auto_create_index: false
        ```
        - 특정 컬럼의 자동 매핑 생성 비활성화
        ```yaml
        index.mapper.dynamic: false
        ```

- 인덱스 관리 API
    - 인덱스의 추가, 삭제를 할 수 있다.
    - 인덱스의 생성
        - 명령어
        ```shell
        PUT /{index명}
        {
          "settings" : {
            "number_of_shards" : 3,
            "number_of_replicas" : 2
          },
          "mappings" : {
            "_docs" : {
              "properties" : {
                "field1" : { "type" :  "integer" },
                "field2" : { "type" :  "text" },
                "field3" : { "type" :  "date" },
                "field4" : { "type" :  "keyword" }
              }
            }
          }       
        }
        ```
        - 매핑이라는 세부 설정을 이용
            - 매핑은 문서와 문서에 포함된 필드, 필드의 타입등을 세세하게 지정할 수 있다.
        - 한번 생성된 매핑 정보는 변경할 수 없다는 단점이 있다.
        - 잘못 생성하거나 변경을 하려는 경우, 데이터를 삭제하고 다시 색인해야 한다.
        - 단순히 문자열로 저장하고 싶은 경우 keyword 타입을 사용, `형태소 분석을 원하는 경우 text 타입`을 사용한다.
        - 코드 값과 연도는 숫자 데이터 타입과 날짜 타입으로 지정
        - 그외에 특별하지 않은 문자열은 keyword 타입으로 지정
    - 인덱스의 삭제
        - 명령어
        ```shell
        DELETE /{index명}
        ```
        - 인덱스를 한 번 삭제하면 다시 복구할 수 없기 때문에 인덱스 삭제는 신중하게 해야 한다는 점이다.

- 문서 관리 API
    - 문서의 추가 / 수정 / 삭제
    - 문서의 ID를 기준으로 한 건의 문서를 다루는 Single document API
        - Index API: 한 건의 문서를 색인
        - Get API: 한 건의 문서를 조회
        - Delete API: 한 건의 문서를 삭제
        - Update API: 한 건의 문서를 업데이트
    - 다수의 문서를 처리하는 Multi-document API
        - Multi Get API: 다수의 문서를 조회
        - Bulk API: 대량의 문서를 색인
        - Delete By Query API: 다수의 문서를 삭제
        - Update By Query API: 다수의 문서를 업데이트
        - Reindex API: 인덱스의 문서를 다시 색인
    - 문서의 생성
        ```shell
        POST /{index명}/_doc/1
        ```
    - 문서의 조회
        ```shell
        GET /{index명}/_doc/1
        ```
    - 문서의 삭제
        ```shell
        DELETE /{index명}/_doc/1
        ```
    - 문서의 생성에서 ID를 부여하지 않고 생성하는 경우의 문제점
        - 문서를 생성할 때 ID를 부여하지 않을 경우 UUID를 생성하여 자동으로 ID가 부여되나 해당 문서를 검색 및 업데이트를 하려는 경우 문제가 발생할 수 있다.
        - 검색엔진은 해당 데이터베이스와 주기적으로 동기화해야 하기 때문에 변경된 내용을 따라 동기화돼야 할 것이다.
        - 색인된 _id 값을 데이터베이스의 PK 혹은 식별이 되는 키 값과 매칭한 정보가 어딘가에는 저장되어 관리되어야 한다.
        - 대용량 데이터를 사용하는 경우 _id 값은 업데이트를 고려하여 데이터베이스 테이블의 식별 값과 맞춰 주는 것이 중요하다.

- 검색 API
    - 문서 조회
    - 엘라스틱 서치 검색 API의 사용방식 두 가지
        ```text
        1. HTTP URI(Uniform Resource Identifier) 형태의 파라미터를 URI에 추가해 검색하는 방법
        2. RESTful API 방식인 QueryDSL을 사용해 요청 본문(Request Body)에 질의 내용을 추가해 검색하는 방법
        ```
    - Request Body 방식은 URI 방식보다 제약사항이 적기 때문에 Request Body 방식을 선호한다.
    - URI 방식은 간단한 쿼리 검색을 하거나 디버깅할 때 간편하게 사용하는 경우에 종종 이용된다.
    - 두 가지 표현식을 모두 사용하는 경우
        ```shell
        GET /{index명}/_doc/_search?q=필드명:검색키워드&pretty=true
        {
            "sort" : {
                "필드명" : {
                    "order" : "asc"
                }
            }
        }
        ```
    - QueryDSL을 사용하면 가독성이 높고, JSON 형식으로 다양한 표현이 가능해진다.
    - Query의 조건을 여러 개 만들거나, 통계를 위한 집계(Aggregation) 쿼리 등 복잡한 쿼리를 작성하려면 QueryDSL을 사용하는 것이 좋다.
    - URI 방식의 검색 질의
        - URI 방식의 검색 질의는 문서 ID인 _id 값을 사용해 문서를 조회하는 방식이다.
        ```shell
        GET /{index명}/_doc/docId?pretty=true
        ```
        - q 파라미터를 사용해 해당 용어와 일치하는 문서만 조회
            ```shell
            GET /{index명}/_search?q=장편
            ```
            - 검색 조건을 통해 조회하는 경우 _shards 에서 성공적으로 반환한 샤드의 수와 실패한 샤드의 수를 알 수 있다.
            - hits에서는 일치하는 문서의 수와 함께 점수(_score)가 가장 높은 상위 10개의 문서를 보여준다.
            - `검색에 실패한 샤드의 수는 검색 시 설정된 time_out에 따라 결정된다.`
            - `time_out 시간이 초과되면 그때까지 검색된 내용까지만 검색 결과로 반환한다.`
            - `따라서 실패한 샤드의 수가 지나치게 많다면 time_out 시간을 적절히 조정해야 한다.`

        - q 파라미터를 사용할 때 별도의 필드명을 지정하지 않으면 존재하는 모든 필드를 대상으로 검색을 수행한한다.
        - 특정 필드만 조회하고 싶다면 다음 코드와 같이 필드명을 포함해서 요청하면 된다.
            ```shell
            POST /인덱스명/_search?q=필드명:검색키워드
            ```
        - Request Body 방식의 검색 질의
            ```shell
            POST /{index명}/_search
            {
              JSON 구문
            }
            POST /{index명}/_search
            {
              "query" : {
                "term" : { "{field명}" : "{키워드}"}
              }
            }
            ```
        - 키의 종류
            ```shell
            {
              size: # 몇개의 결과를 반환할 지 결정한다. (기본 값은 10)
              from: # 어느 위치부터 반롼할 지 결정한다.
                    # 0부터 시작하면 상위 10건의 데이터를 반환한다. (기본 값은 0)
              _source: # 특정 필드만 결과로 반환하고 싶을 때 사용한다.
              sort: # 특정 필드를 기준으로 정렬한다.
              query: {
                # 검색될 조건을 정의
              }
              filter: {
                # 검색 결과 중 특정한 값을 다시 보여준다.
                # 결과 내에서 재검색할 때 사용하는 기능 중 하나이다.
                # 다만 필터를 사용하게 되면 자동으로 source 값이 정렬되지 않는다.
              }
            }
            ```

- 집계 API
    - 문서 통계
    - 집계 API는 기본적으로 메모리 기반으로 동작하기 때문에 대용량의 데이터 통계 작업이 가능하다.
    - 쿼리에 사용되는 집계에 따라 수치를 계산하고 동적으로 카운팅하거나 히스토그램 같은 작업 등도 할 수 있게 바뀌었다.
    - 데이터 집계 (_search를 사용하여 집계, terms 키워드를 이용해 그룹화)
        ```shell
        POST /{index명}/_search?size=0
        {
          "aggs": {
            "{group명 정의}" : {
              "terms" : {
                "field": "{그룹화할 필드명}"
              }
            }
          }
        }
        ```
    - 버킷 안에 다른 버킷의 결과를 추가하는 데이터 집계
        ```shell
        POST /{index명}/_search?size=0
        {
          "aggs": {
            "{group명 정의1}" : {
              "terms" : {
                "field": "{그룹화할 필드명}"
              },
              "aggs": {
                "{group명 정의2}" : {
                  "terms" : {
                    "field": "{그룹화할 필드명}"
                  },
                  
                }
              }
            }
          }
        }
        ```
    - 데이터 집계 타입
        - 버킷 집계(Bucket Aggregation)
            - 집계 중 가장 많이 사용하는 방식
            - 문서의 `필드`를 기준으로 버킷을 집계
        - 메트릭 집계(Metric Aggregation)
            - 문서에서 추출된 값을 가지고 Sum, Max, Min, Avg를 계산
        - 매트릭스 집계(Matrix Aggregation)
            - 행렬의 값을 합하거나 곱한다.
        - 파이프라인 집계(Pipeline Aggregation)
            - 버킷에서 도출된 결과 문서를 다른 필드 값으로 재분류한다.
            - 즉, 다른 집계에 의해 생성된 출력 결과를 다시 한 번 집계한다.

### 3 데이터 모델링
- 색인 시 문서의 데이터 유형에 따라 필드에 적절한 데이터 타입을 지정하는 작업을 `매핑`이라 한다.
- 색인될 문서의 `데이터 모델링`이라고도 한다.
- 사전에 매핑을 설정하면 지정된 데이터 타입으로 색인되지만 매핑을 설정해 두지 않으면 엘라스틱서치가 자동으로 필드를 생성하고 필드 타입까지 결정한다.


> 매핑 API 이해하기
- 매핑은 색인 시 데이터가 어디에 어떻게 저장될지를 결정하는 설정
- 데이터베이스의 스키마에 대응하는 개념으로 인덱스에 추가되는 각 데이터 타입으로 구체적으로 정의하는 일
- 문서에 존재하는 필드의 속성을 정의할 때 각 필드 속성에는 `데이터 타입`과 `메타데이터`가 포함된다.
- 이를 통해 색인 과정에서 문서가 어떻게 역색인(Inverted Index)으로 변환되는지를 상세하게 정의할 수 있다.

- **스키마리스를 사용시 주의할 점**
    - 엘라스틱서치는 기본적으로 스키마리스이기 때문에 명시적으로 필드를 정의하지 않아도 데이터 유형에 따라 필드 데이터 타입에 대한 매핑 정보가 자동 생성된다.
    - 동적 매핑을 하게 되면 문서에 새로운 필드가 추가될 때마다 인덱스가 자동으로 업데이터 되기 때문에 쉽고 편리하지만 
      한번 정의된 필드에 서로 다른 타입의 데이터가 입력된다면 뒤에 입력딘 데이터의 색인 생성에 실패한다.
    - **매핑 정보를 설정할 때 고민할 점**
        - 문자열을 분석할 것인가?
        - `_source`에 어떤 필드를 정의할 것인가?
        - 날짜 필드를 가지는 필드는 무엇인가?
        - 매핑에 정의되지 않고 유입되는 필드는 어떻게 처리할 것인가?

- 매핑 인덱스 만들기
    - 실제 검색 대상이 되는 필드는 분석 가능하도록 text 타입으로 정의
    - 해당 정보를 그대로 조회하기 위해 integer, keyword 타입으로 정의
    - 특정 필드에 내부적으로 또 다른 문서 구조를 갖도록 정의하여 계층형 구조로 설정이 가능

- 매핑 확인
    -
- 매핑 파라미터
> 매타 필드
- `_index` 메타 필드
- `_type` 메타 필드
- `_id` 메타 필드
- `_uid` 메타 필드
- `_source` 메타 필드
- `_all` 메타 필드
- `_routing` 메타 필드
> 필드 데이터 타입
- Keyword 데이터 타입
- Text 데이터 타입
- Array 데이터 타입
- Numeric 데이터 타입
- Date 데이터 타입
- Range 데이터 타입
- Boolean 데이터 타입
- Geo-Point 데이터 타입
- IP 데이터 타입
- Object 데이터 타입
- Nested 데이터 타입
> 엘라스틱 서치 분석기
- 텍스트 분석 개요
- 역색인 구조
- 분석기의 구조
- 전처리 필터
- Tokenizer 필터
- Token 필터
- 동의어 사전
> Document API 이해하기
- 문서 파라미터
- Index API
- Get API
- Delete API
- Delete By Query API
- Update API
- Bulk API
- ReIndex API
