# 엘라스틱 서치 실무 가이드

## 1. 검색 시스템 이해하기
- 전체 흐름
    - 검색엔진으로서 엘라스틱 서치의 이해
    - 데이터의 모델링
    - 데이터의 검색 방법과 효율성 제고
    - 데이터를 그룹화하고 통계치를 얻는 집계
    - 엘라스틱 서치의 기반 기술인 루씬
    - 안정된 클러스터 운영

### 1.1 검색시스템의 이해
검색 시스템과 검색엔진의 정의, 검색엔진인 엘라스틱 서치와 데이터베이스의 차이

> 검색 시스템이란?
- 검색엔진이란 광활한 웹에서 정보를 수집해 검색 결과를 제공하는 프로그램
- 검색시스템은 대용량 데이터를 기반으로 신회성있는 검색결과를 제공하기 위해 검색엔진을 기반으로 구축된 시스템을 통칭하는 용어
    - 수집기를 이용한 데이터 수집, 다수의 검색엔진을 이용한 색인, 검색 결과를 UI로 제공
    - 시스템 내부의 정책에 따라 특정 필드나 문서에 가중치를 둔 검색 정확도

> 검색 시스템의 구성 요소

- 정보를 수집하는 수집기
- 수집한 데이터를 저장하는 스토리지
- 수집한 데이터를 검색에 적절한 형태로 변환하는 색인기
- 색인된 데이터에서 일치하는 문서를 찾는 검색기

- 수집기
    - 파일, 데이터베이스, 웹페이지 등 웹 상의 대부분의 정보가 수집대상이다.
    - 파일의 경우 수집기가 파일명, 파일 내용, 파일 경로 등의 정보를 수집하여 저장하면 검색엔진이 저장된 정보를 검색하여 질의에 응답하게 된다.
- 스토리지
    - 데이터베이스에서 데이터를 저장하는 물리적인 저장소
- 색인기
    - 수집된 데이터를 검색 가능한 구조로 가공하고 저장
    - 다양한 형태소 분석기를 조합해 정보에서 의미가 있는 용어를 추출, 검색에 유리한 역색인 구조로 데이터를 저장
- 검색기
    - 사용자의 질의를 입력받아 색인기에서 저장한 역색인 구조에서 일치하는 문서를 찾아 결과로 반환
    - 질의와 문서가 일치하는지는 유사도 기반의 검색 순위 알고리즘으로 판단
    - 검색기 또한 색인기와 마찬가지로 형태소 분석기를 이용해 사용자 질의에서 유의미한 용어를 추출해 검색
        - 사용하는 형태소 분석기에 따라 검색 품질 차이가 발생할 수 있다.

> 관계형 데이터베이스와의 차이점
- 관계형 데이터베이스의 특징
    - 데이터를 통합 관리하는 데이터의 집합
    - 저장 방식에 따라 크게 관계형 또는 계층형 데이터베이스로 구분
    - 모든 데이터베이스는 중복을 제거하고, 정형 데이터로 구조화해 행과 열로 구성된 테이블에 저장
    - SQL 문을 이용해 원하는 정보의 검색이 가능하나 텍스트 매칭을 통한 단순한 검색만 가능
    - 텍스트를 여러 단어로 변형하거나 여러 개의 동의어나 유의어를 활용한 검색은 불가능
- 검색엔진의 특징
    - 비정형 데이터를 색인하고 검색
    - 형태소 분석을 통해 사람이 구사하는 자연어의 처리가 가능
    - 역색인 구조를 바탕으로 빠른 검색 속도를 보장

- 용어 구분

    |엘라스틱서치|관계형 데이터베이스|
    |:---:|:---:|
    |인덱스(Index)|데이터베이스(Database)|
    |샤드(shard)|파티션(partition)|
    |타입(type)|테이블(table)|
    |문서(document)|행(row)|
    |필드(field)|열(column)|
    |매핑(mapping)|스키마(schema)|
    |Query DSL|SQL|
    
    ```text
    * 관계형데이터베이스의 인덱스는 where 절의 쿼리와 join을 빠르게 만드는 보조 데이터 도구로 사용
    * 6.0 이하 버전 하나의 인덱스 내부에 기능에 따라 데이터를 분류하고 여러 개의 타입을 만들어 사용
    * 현재는 하나의 인덱스에 하나의 타입만 구성하도록 변경
    ```

- 요청 방식 차이 

    |기능|엘라스틱서치|데이터베이스|
    |:----:|:----:|:----:|
    |데이터의 조회|GET|SELECT|
    |데이터의 생성|PUT|INSERT|
    |인덱스 업데이트, 데이터 조회|POST|UPDATE, SELECT|
    |데이터 삭제|DELETE|DELETE|
    |인덱스의 정보 확인|HEAD|-|

    ```text
    * RESTful API
    HTTP 헤더(header)와 URL만 사용해 다양한 형태의 요청을 할 수 있는 HTTP 프로토콜을 최대한 활용하도록 고안된 아키텍처
    ```

    - 엘라스틱 서치를 사용하기 위한 간단한 API 요청 구조
    
    ```shell
    curl -X(method) http://host:port/(index)/(type)/(document id) -d '{json data}'
    ```

### 1.2. 검색 시스템과 엘라스틱서치

> 엘라스틱 서치가 강력한 이유
- 오픈소스 검색엔진
- 전문 검색
- 통계 분석
- 스키마리스
- RESTful API
- 멀티테넌시(Multi-tenancy)
- Document-Oriented
- 역색인(Inverted Index)
- 확장성과 가용성

> 엘라스틱 서치의 약점
- '실시간'이 아닌점
- 트랜잭션과 롤백 기능을 제공하지 않는다.
- 데이터의 업데이트를 제공하지 않는다.
    

### 1.3 실습 환경 구축
> 엘라스틱 서치 설치
- 자바 설치
- 엘라스틱 서치 설치시 사용자 계정을 생성후 설치 권장
    ```json
    {
      "name": "b93c3535b922",
      "cluster_name": "docker-cluster",
      "cluster_uuid": "2Ql712GMTNyQBaVy0Upz9A",
      "version": {
        "number": "7.9.3",
        "build_flavor": "default",
        "build_type": "docker",
        "build_hash": "c4138e51121ef06a6404866cddc601906fe5c868",
        "build_date": "2020-10-16T10:36:16.141335Z",
        "build_snapshot": false,
        "lucene_version": "8.6.2",
        "minimum_wire_compatibility_version": "6.8.0",
        "minimum_index_compatibility_version": "6.0.0-beta1"
      },
      "tagline": "You Know, for Search"
    }
    ```

- 주요 설정 항목

    |속성명|설명|
    |:---|:---|
    |`cluster.name`|클러스터로 여러 노드를 하나로 묶기 위해 클러스터 명을 등록|
    |`node.master`|마스터 노드로 동작 여부를 지정|
    |`node.data`|데이터 노드로 동작 여부를 지정|
    |`node.name`|엘라스틱 서치 노드명을 설정, 미설정시 임의값을 설정|
    |`path.data`|엘라스틱 서치의 인덱스 경로를 지정, 미설정시 data 디렉토리에 인덱스 생성|
    |`path.logs`|엘라스틱 서치의 노드와 클러스터에서 생성되는 로그를 저장할 경로를 지정, 기본 경로는 `/path/to/logs`|
    |`path.repo`|엘라스틱서치 인덱스를 백업하기 위한 스냅샷의 경로를 지정|
    |`network.hosts`|특정 IP만 엘라스틱서치에 접근하도록 허용, 모든 IP 허용시 `0.0.0.0`, IP 값으로 `127.0.0.1`을 설정 시 개발 모드에서 프로덕트 모드로 자동 변경|
    |`http.port`|엘라스틱 서치 서버에 접근할 수 있는 HTTP API 호출을 위한 포트 번호 지정, 기본값은 `9200`|
    |`transport.tcp.port`|엘라스틱서치 클라이언트가 접근할 수 있는 TCP 포트, 기본값은 `9300`|
    |`discovery.zen.ping.unicast.hosts`|노트가 여러개인 경우 유니캐스트로 활성화된 다른 서버를 찾는다. 클러스터로 묶인 노드(서버)의 IP를 지정하면된다.|
    |`discovery.zen.minimum_master_nodes`|마스터 노드의 선출 기준이 되는 노드의 수를 지정|

> 키바나 설치
- 데이터 시각화 프로그램
- 엘라스틱 서치에 색인된 데이터를 검색하거나, 문서를 추가한다거나 삭제하는 등의 기능을 손쉽게 구현할 수 있다.
- Dev Tools 메뉴에서 문서와 매핑의 추가, 삭제 등의 작업을 JSON 포맷으로 엘라스틱서치에 요청할 수 있다.
- Kibana > Dev Tools > curl 요청 구조
    ```text
    GET _search
    {
        "query": {
            "match_all": {}
        }
    }
    ```
- `GET`: 요청 전달 방식 중 하나로 어떠한 변경 없이 쿼리에 대한 결과를 반환 받는 용도
- `_search`: 검색 쿼리를 의미, `_search` 앞 부분에 인덱스를 명시하여 해당 인덱스로만 범위를 한정해서 검색을 수행할 수도 있다.
    - 여기서는 어떠한 인덱스도 지정하지 않았기 때문에 전체 인덱스를 대상으로 검색이 수행된다.
    - size가 기본값 01으로 설정되어 있기 때문에 검색 결과로 10개의 문서만 반환하기 때문에 많은 양의 문서가 색인되어 있더라도 결과가 빠르게 반환된다.
    - curl 명령어에서는 -X 옵션 다음으로 지정했던 도메인 부분에 해당한다.
    - 키바나를 통해 전달되는 쿼리는 무조건 설정에 지정된 엘라스틱 서치로 전달되기 때문에 생략가능
  
- `{...}`: 쿼리 본문에 해당하며 모든 문서를 검색, curl 명령어에서는 -d 옵션에 해당

## 2 엘라스틱 서치 살펴보기

### 2.1 엘라스틱 서치를 구성하는 개념

분산 시스템을 지향하는 엘라스틱 서치의 전체적인 아키텍처에 대한 이해

- 기본 용어
    - 인덱스, 타입 문서, 필드로 구성
    - @인덱스
        - 데이터 저장 공간
        - 하나의 인덱스는 하나의 타입을 가지며, 하나의 물리적인 노드에 여러 개의 논리적인 인덱스를 생성할 수 있다.
        - 검색 시 인덱스 이름으로 문서를 검색, 여러 인덱스를 동시에 검색하는 것도 가능
        - 엘라스틱 서치를 분산환경으로 구성하는 경우, 하나의 인덱스가 여러 노드에 분산되어 저장되어 관리가 된다.
        - 엘라스틱 서치는 인덱스 생성 시 기본적으로 5개의 프라이머리 샤드와 1개의 레플리카 샤드 세트를 생성한다.
        - 인덱스 이름은 모두 소문자여야 하며 추가, 수정, 삭제, 검색은 RESTful API로 수행이 가능하다.
        - `만약 인덱스가 없는 상태에서 데이터가 추가된다면 데이터를 이용해 인덱스가 자동으로 생성된다.`
    - @샤드
        - 색인된 문서는 하나의 인덱스에 담긴다. 인덱스 내부에 색인된 데이터는 물리적인 공간에 여러 개의 파티션으로 나뉘어 구성되는데, 이 파티션을 엘라스틱 서치에서는 샤드라 부른다.
        - 엘라스틱 서치는 다수의 샤드로 문서를 분산 저장하고 있어 데이터 손실 위험을 최소화할 수 있다.
    - @타입
        - 타입(Type)은 인덱스의 논리적 구조를 의마하며, 인덱스 속성에 따라 분류하기도 한다.
        - 6.1 버전 부터는 인덱스당 하나의 타입만을 사용할 수 있다.
    - @문서
        - 문서는 엘라스틱 서치에서 데이터가 저장되는 최소 단위이다.
        - 기본적으로 JSON 포맷으로 데이터가 저장된다.
        - 데이터베이스와 비교하자면 테이블의 행이 엘라스틱 서치의 문서에 해당한다고 볼 수 있다.
        - 하나의 문서는 다수의 필드로 구성돼 있는데 각 필드는 데이터의 형태에 따라 용도에 맞는 데이터 타입(Data Type)을 정의해야 한다.
        - 또한 문서는 중첩 구조를 지원하기 때문에 이를 이용해 문서 안에 문서를 지정하는 것도 가능하다.
    - @필드
        - 필드는 문서를 구성하기 위한 속성
        - 일반적으로 데이터베이스의 컬럼과 비교할 수 있으나, 컬럼이 정적인 데이터 탕비인데 반해 필드는 좀 더 동적인 데이터 타입이라 할 수 있다.
        - 하나의 필드는 목적에 따라 다수의 데이터 타입을 가질 수 있다. 
          ex) 매칭 검색, 초성 검색을 지원할 수 있도록 2개의 데이터 타입을 정의하는 것이 가능
    - @매핑
        - 문서의 필드와 필드의 속성을 정의, 그에 따른 색인 방버븡 정의하는 프로세스
        - 인덱스의 매핑 정보에는 여러 가지 데이터 타입을 지정할 수 있지만 필드명은 중복해서 사용할 수 없다.

- 노드의 종류
    - @클러스터는 물리적인 노드 인스턴스들의 모임이라 할 수 있다.
    - 클러스터는 모든 노드의 검색과 색인 작업을 관장하는 논리적인 개념이라 할 수 있다.
    - 관계형 데이터베이스의 경우 모든 요청을 서버 하나에서 처리하여 결과를 제공하지만 엘라스틱 서치의 경우에는 다수의 서버로 분산해서 처리하는 것이 가능하여 대용량 데이터를 처리할 수 있다.
    - 분산 처리를 위해서는 다양한 형태의 노드들을 조합하여 클러스터를 구성해야 한다.
    - 기본적으로 마스터 노드가 전체적인 클러스터를 관리하고 데이터 노드가 실제 데이터를 관리한다.
    - 4가지 유형의 노드

        |노드명|용도|
        |:---|:---|
        |마스터노드(Master Node)|- 클러스터를 관리 <br/>- 노드 추가와 제거 같은 클러스터의 전반적인 관리를 담당한다.|
        |데이터 노드(Data Node)|- 실질적인 데이터를 저장한다. <br/>- 검색과 통계 같은 데이터 관련 작업을 수행한다.|
        |코디네이팅 노드(Coordinating Node)|- 사용자의 요청만 받아서 처리 <br/>- 클러스터 관련 요청은 마스터 노드에 전달하고 데이터 관련 요청은 데이터 노드에 전달한다.|
        |인제스트 노드(Ingest Node)|- 문서의 전처리 작업을 담당한다. <br/> - 인덱스 생성 전 문서의 형식을 다양하게 변경할 수 있다.|
        
        - 설정에 따라 각 노드는 한 가지 유형으로 동작할 수도 있고 여러 개의 유형을 겸해서 동작할 수 있다.
    
    - 마스터 노드(Master Node)
        - 인덱스를 생성, 삭제하는 등 클러스터와 관련된 전반적인 작업을 담당한다.
        - 위와 같은 역할을 수행하기 위해서 네트워크 속도가 빠르고 지연이 없는 노드를 마스터 노드로 선정해야 한다.
        - 다수의 노드를 마스터 노드로 성정할 수 있지만 결과적으로 하나의 노드만이 마스터 노드로 선출되어 동작한다.
        - 마스터 노드 전용으로 설정하는 방법
            - `conf/elasticsearch.yml`
            ```yaml
            node.master: true
            node.data: false
            node.ingest: false
            search.remote.connect: false
            ```
    - 데이터 노드(Data Node)
        - 데이터 노드는 문서가 실제로 저장되는 노드
        - 데이터가 실제로 분산 저장되는 물리적 공간인 샤드가 배치되는 노드
        - 색인 작업은 CPU, 메모리, 스토리지 같은 컴퓨팅 리소스를 많이 소모하기 때문에 리소스 모니터링을 필요로한다.
        - 데이터 노드는 가능한 마스터 노드와 분리해서 구성하는 것이 좋다.
        - 단 색인할 문서의 수가 적으면 함께 구성해도 상관은 없다.
        - 데이터 노드로 성정하는 방법
            - `conf/elasticsearch.yml`
            ```yaml
            node.master: false
            node.data: true
            node.ingest: false
            search.remote.connect: false
            ```
    - 코디네이팅 노드(Coordinating Node)
        - 데이터 노드, 마스터 노드, 인제스트 노드의 역할을 하지 않고, 들어온 요청을 단순히 라운드로빈 방식으로 분산시켜 주는 노드이다.
        - 코디네이팅 노드로 설정하는 방법
            - `conf/elasticsearch.yml`
            ```yaml
            node.master: false
            node.data: false
            node.ingest: false
            search.remote.connect: false
            ```
    - 인제스트 노드(Ingest Node)
        - 색인 전 데이터를 전처리 하기 위한 노드
        - 데이터의 포맷을 변경하기 위해 스크립트로 전처리 파이프라인을 구성하고 실행할 수 있다.
            - `conf/elasticsearch.yml`
            ```yaml
            node.master: false
            node.data: false
            node.ingest: true
            search.remote.connect: false
            ```

- 클러스터, 노드, 샤드
    - 클러스터와 노드의 관계 (하나의 클러스터에 노드1, 노드2로 구성되는 경우)
        - 엘라스틱 서치 클러스터는 인덱스의 문서를 조회할 때 마스터 노드를 통해 2개의 노드를 모두 조회하여 각 데이터를 취합한 후 결과를 하나로 합쳐 제공한다.
        - 현재는 하나의 클러스터로만 구성되어 있지만 여러 개의 클러스터를 연결하여 구성할 수도 있다.
            - 두 개 이상의 클러스터로 구성하는 경우 각 클러스터 명으로 구분되며 명시하지 않는 경우 임의 문자열로 지정된다.
        - `클러스터에 있는 노드는 실시간으로 추가, 제거가 가능하여 가용성, 확장성 측면에서 매우 유연하다.`
    - 클러스터의 동작 방식 이해 (하나의 클러스터에 3개의 노드로 구성되는 경우)
        - 프라미머리 샤드와 레플리카 샤드의 수를 조정하며 인덱스 생성 시 클러스터가 어떻게 동작하는지 분석
        - 프라이머리 샤드 3개, 레플리카 샤드 0개를 세트로 구성하는 경우
            ```json
            {
              "settings": {
                "index": {
                  "number_of_shards": 3,
                  "number_of_replicas": 0
                }
              }
            }
            ```
            - 샤드는 분산된 데이터에 따라 순차적인 번호를 가진다.
            - 일반적으로 프라이머리 샤드느 안정성을 위해 하나의 노드에 하나씩 분산된다.
            - 인덱스에 다수의 문서를 색인하게 되면 문서는 3개의 샤드 골고루 분산 저장한다.
              
        - 프라이머리 샤드 6개, 레플리카 샤드 0개를 세트로 구성하는 경우
            ```json
            {
              "settings": {
                "index": {
                  "number_of_shards": 6,
                  "number_of_replicas": 0
                }
              }
            }
            ```
            - 3개의 노드에 프라이머리 샤드 6개가 노드당 2개가 배치되며, 색인 시 6개의 샤드에 데이터가 분산된다.

        - 프라이머리 샤드 3개, 레플리카 샤드 1개 세트 구성
            - 레플리카 샤드는 프라이머리 샤드의 복제본이다.
            ```json
            {
              "settings": {
                "index": {
                  "number_of_shards": 3,
                  "number_of_replicas": 1
                }
              }
            }
            ```
            - 엘라스틱 서치는 장애 시 레플리카 샤드를 이용해 샤드를 복구한다.
            - 프라이머리 샤드와 레플리카 샤드가 서로 다른 노드에 배치된다.

        - 프라이머리 샤드 3개, 레플리카 샤드 3개 세트 구성
            - 레플리카 샤드는 프라이머리 샤드의 복제본이다.
            ```json
            {
              "settings": {
                "index": {
                  "number_of_shards": 3,
                  "number_of_replicas": 3
                }
              }
            }
            ```
            - 프라이머리 샤드의 복제본이 존재하기 때문에 물리적인 노드 하나가 죽더라도 나머지 노드 2개가 전체 데이터를 복구할 수 있다.
            - 장애가 발생하면 마스터 노트드는 데이터를 재분배하거나 레플리카 샤드를 프라이이머리 샤드로 승격시켜 서비스 중단 없는 복구가 가능해진다.
        - `장애극복(Failover) 상황을 염두에 두고 노드와 샤드의 수를 적절하게 구성해야 한다.`

### 2.2 엘라스틱서치에서 제공하는 주요 API
- 문서를 색인하기 위해서는 기본적으로 인덱스를 생성해야 한다.
- 인덱스를 통해 입력되는 문서의 필드를 정의하고, 각 필드에 알맞은 데이터 타입을 지정해야 한다.
- index vs indices
    - index: 색인된 데이터
    - indexing: 색인하는 과정
    - indices: 매핑 정보를 저장하는 논리적인 데이터 공간

- 스키마리스
    - 문서를 색인하기 위해서는 기본적으로 인덱스를 생성하는 과정이 필요한데, 인덱스를 생성하는 과정 없이 문서를 추가하더라도 문서가 색인되도록 지원하는 기능
    - 최초 문서가 색인될 때 인덱스의 존재여부를 확인하고 인덱스가 존재하지 않는다면 문서를 분석해서 문서가 색인될 수 있도록 인덱스를 자동 생성하는 기능
    - 이는 성능과 밀접한 연관이 있기 때문에 특수한 상황 및 데이터 구조와 검색방식을 확실히 이해하고 사용해야 한다.
    - 인덱스를 자동 생성하는 경우 특정 단어를 검색할 때 검색 결과에서 누락되는 등 문제가 발생할 가능성이 높다.
    - 기본적으로 모든 필드가 text 타입과 keyword 타입을 동시에 제공하는 멀티필드 기능으로 구성된다.
    - 모든 필드가 text 타입 필드와 keyword 타입 필드를 동시에 필요로 하지않으므로 공간의 낭비를 초래한다.
    - 이 경우 검색 품질이 떨어지거나 성능상 문제가 발생할 가능성이 커진다.
    - 스키마리스를 이용해 색인한다면 기본적으로 text 타입의 Standard Analyzer를 사용하는 데이터 타입이 정의된다.
        - 이 경우 분석기가 문자열을 토큰으로 분리하여 Term이 생성되고 검색시 정확하게 matching 되는 키워드만 검색하게 될 것이다.
        - 원하는 결과를 얻기 위해서는 한글 형태소를 분석하는 분석기를 사용하도록 데이터 타입을 직접 정의해야 한다.
    - 스키마리스 사용 중지 방법
        - 노드 설정 파일 수정
        - 자동 인덱스 생성 기능 비활성화
        ```yaml
        action.auto_create_index: false
        ```
        - 특정 컬럼의 자동 매핑 생성 비활성화
        ```yaml
        index.mapper.dynamic: false
        ```

- 인덱스 관리 API
    - 인덱스의 추가, 삭제를 할 수 있다.
    - 인덱스의 생성
        - 명령어
        ```shell
        PUT /{index명}
        {
          "settings" : {
            "number_of_shards" : 3,
            "number_of_replicas" : 2
          },
          "mappings" : {
            "_docs" : {
              "properties" : {
                "field1" : { "type" :  "integer" },
                "field2" : { "type" :  "text" },
                "field3" : { "type" :  "date" },
                "field4" : { "type" :  "keyword" }
              }
            }
          }       
        }
        ```
        - 매핑이라는 세부 설정을 이용
            - 매핑은 문서와 문서에 포함된 필드, 필드의 타입등을 세세하게 지정할 수 있다.
        - 한번 생성된 매핑 정보는 변경할 수 없다는 단점이 있다.
        - 잘못 생성하거나 변경을 하려는 경우, 데이터를 삭제하고 다시 색인해야 한다.
        - 단순히 문자열로 저장하고 싶은 경우 keyword 타입을 사용, `형태소 분석을 원하는 경우 text 타입`을 사용한다.
        - 코드 값과 연도는 숫자 데이터 타입과 날짜 타입으로 지정
        - 그외에 특별하지 않은 문자열은 keyword 타입으로 지정
    - 인덱스의 삭제
        - 명령어
        ```shell
        DELETE /{index명}
        ```
        - 인덱스를 한 번 삭제하면 다시 복구할 수 없기 때문에 인덱스 삭제는 신중하게 해야 한다는 점이다.

- 문서 관리 API
    - 문서의 추가 / 수정 / 삭제
    - 문서의 ID를 기준으로 한 건의 문서를 다루는 Single document API
        - Index API: 한 건의 문서를 색인
        - Get API: 한 건의 문서를 조회
        - Delete API: 한 건의 문서를 삭제
        - Update API: 한 건의 문서를 업데이트
    - 다수의 문서를 처리하는 Multi-document API
        - Multi Get API: 다수의 문서를 조회
        - Bulk API: 대량의 문서를 색인
        - Delete By Query API: 다수의 문서를 삭제
        - Update By Query API: 다수의 문서를 업데이트
        - Reindex API: 인덱스의 문서를 다시 색인
    - 문서의 생성
        ```shell
        POST /{index명}/_doc/1
        ```
    - 문서의 조회
        ```shell
        GET /{index명}/_doc/1
        ```
    - 문서의 삭제
        ```shell
        DELETE /{index명}/_doc/1
        ```
    - 문서의 생성에서 ID를 부여하지 않고 생성하는 경우의 문제점
        - 문서를 생성할 때 ID를 부여하지 않을 경우 UUID를 생성하여 자동으로 ID가 부여되나 해당 문서를 검색 및 업데이트를 하려는 경우 문제가 발생할 수 있다.
        - 검색엔진은 해당 데이터베이스와 주기적으로 동기화해야 하기 때문에 변경된 내용을 따라 동기화돼야 할 것이다.
        - 색인된 _id 값을 데이터베이스의 PK 혹은 식별이 되는 키 값과 매칭한 정보가 어딘가에는 저장되어 관리되어야 한다.
        - 대용량 데이터를 사용하는 경우 _id 값은 업데이트를 고려하여 데이터베이스 테이블의 식별 값과 맞춰 주는 것이 중요하다.

- 검색 API
    - 문서 조회
    - 엘라스틱 서치 검색 API의 사용방식 두 가지
        ```text
        1. HTTP URI(Uniform Resource Identifier) 형태의 파라미터를 URI에 추가해 검색하는 방법
        2. RESTful API 방식인 QueryDSL을 사용해 요청 본문(Request Body)에 질의 내용을 추가해 검색하는 방법
        ```
    - Request Body 방식은 URI 방식보다 제약사항이 적기 때문에 Request Body 방식을 선호한다.
    - URI 방식은 간단한 쿼리 검색을 하거나 디버깅할 때 간편하게 사용하는 경우에 종종 이용된다.
    - 두 가지 표현식을 모두 사용하는 경우
        ```shell
        GET /{index명}/_doc/_search?q=필드명:검색키워드&pretty=true
        {
            "sort" : {
                "필드명" : {
                    "order" : "asc"
                }
            }
        }
        ```
    - QueryDSL을 사용하면 가독성이 높고, JSON 형식으로 다양한 표현이 가능해진다.
    - Query의 조건을 여러 개 만들거나, 통계를 위한 집계(Aggregation) 쿼리 등 복잡한 쿼리를 작성하려면 QueryDSL을 사용하는 것이 좋다.
    - URI 방식의 검색 질의
        - URI 방식의 검색 질의는 문서 ID인 _id 값을 사용해 문서를 조회하는 방식이다.
        ```shell
        GET /{index명}/_doc/docId?pretty=true
        ```
        - q 파라미터를 사용해 해당 용어와 일치하는 문서만 조회
            ```shell
            GET /{index명}/_search?q=장편
            ```
            - 검색 조건을 통해 조회하는 경우 _shards 에서 성공적으로 반환한 샤드의 수와 실패한 샤드의 수를 알 수 있다.
            - hits에서는 일치하는 문서의 수와 함께 점수(_score)가 가장 높은 상위 10개의 문서를 보여준다.
            - `검색에 실패한 샤드의 수는 검색 시 설정된 time_out에 따라 결정된다.`
            - `time_out 시간이 초과되면 그때까지 검색된 내용까지만 검색 결과로 반환한다.`
            - `따라서 실패한 샤드의 수가 지나치게 많다면 time_out 시간을 적절히 조정해야 한다.`

        - q 파라미터를 사용할 때 별도의 필드명을 지정하지 않으면 존재하는 모든 필드를 대상으로 검색을 수행한한다.
        - 특정 필드만 조회하고 싶다면 다음 코드와 같이 필드명을 포함해서 요청하면 된다.
            ```shell
            POST /인덱스명/_search?q=필드명:검색키워드
            ```
        - Request Body 방식의 검색 질의
            ```shell
            POST /{index명}/_search
            {
              JSON 구문
            }
            POST /{index명}/_search
            {
              "query" : {
                "term" : { "{field명}" : "{키워드}"}
              }
            }
            ```
        - 키의 종류
            ```shell
            {
              size: # 몇개의 결과를 반환할 지 결정한다. (기본 값은 10)
              from: # 어느 위치부터 반롼할 지 결정한다.
                    # 0부터 시작하면 상위 10건의 데이터를 반환한다. (기본 값은 0)
              _source: # 특정 필드만 결과로 반환하고 싶을 때 사용한다.
              sort: # 특정 필드를 기준으로 정렬한다.
              query: {
                # 검색될 조건을 정의
              }
              filter: {
                # 검색 결과 중 특정한 값을 다시 보여준다.
                # 결과 내에서 재검색할 때 사용하는 기능 중 하나이다.
                # 다만 필터를 사용하게 되면 자동으로 source 값이 정렬되지 않는다.
              }
            }
            ```

- 집계 API
    - 문서 통계
    - 집계 API는 기본적으로 메모리 기반으로 동작하기 때문에 대용량의 데이터 통계 작업이 가능하다.
    - 쿼리에 사용되는 집계에 따라 수치를 계산하고 동적으로 카운팅하거나 히스토그램 같은 작업 등도 할 수 있게 바뀌었다.
    - 데이터 집계 (_search를 사용하여 집계, terms 키워드를 이용해 그룹화)
        ```shell
        POST /{index명}/_search?size=0
        {
          "aggs": {
            "{group명 정의}" : {
              "terms" : {
                "field": "{그룹화할 필드명}"
              }
            }
          }
        }
        ```
    - 버킷 안에 다른 버킷의 결과를 추가하는 데이터 집계
        ```shell
        POST /{index명}/_search?size=0
        {
          "aggs": {
            "{group명 정의1}" : {
              "terms" : {
                "field": "{그룹화할 필드명}"
              },
              "aggs": {
                "{group명 정의2}" : {
                  "terms" : {
                    "field": "{그룹화할 필드명}"
                  },
                  
                }
              }
            }
          }
        }
        ```
    - 데이터 집계 타입
        - 버킷 집계(Bucket Aggregation)
            - 집계 중 가장 많이 사용하는 방식
            - 문서의 `필드`를 기준으로 버킷을 집계
        - 메트릭 집계(Metric Aggregation)
            - 문서에서 추출된 값을 가지고 Sum, Max, Min, Avg를 계산
        - 매트릭스 집계(Matrix Aggregation)
            - 행렬의 값을 합하거나 곱한다.
        - 파이프라인 집계(Pipeline Aggregation)
            - 버킷에서 도출된 결과 문서를 다른 필드 값으로 재분류한다.
            - 즉, 다른 집계에 의해 생성된 출력 결과를 다시 한 번 집계한다.

## 3 데이터 모델링
- 색인 시 문서의 데이터 유형에 따라 필드에 적절한 데이터 타입을 지정하는 작업을 `매핑`이라 한다.
- 색인될 문서의 `데이터 모델링`이라고도 한다.
- 사전에 매핑을 설정하면 지정된 데이터 타입으로 색인되지만 매핑을 설정해 두지 않으면 엘라스틱서치가 자동으로 필드를 생성하고 필드 타입까지 결정한다.


### 3.1 매핑 API 이해하기
- 매핑은 색인 시 데이터가 어디에 어떻게 저장될지를 결정하는 설정
- 데이터베이스의 스키마에 대응하는 개념으로 인덱스에 추가되는 각 데이터 타입으로 구체적으로 정의하는 일
- 문서에 존재하는 필드의 속성을 정의할 때 각 필드 속성에는 `데이터 타입`과 `메타데이터`가 포함된다.
- 이를 통해 색인 과정에서 문서가 어떻게 역색인(Inverted Index)으로 변환되는지를 상세하게 정의할 수 있다.

- **스키마리스를 사용시 주의할 점**
    - 엘라스틱서치는 기본적으로 스키마리스이기 때문에 명시적으로 필드를 정의하지 않아도 데이터 유형에 따라 필드 데이터 타입에 대한 매핑 정보가 자동 생성된다.
    - 동적 매핑을 하게 되면 문서에 새로운 필드가 추가될 때마다 인덱스가 자동으로 업데이터 되기 때문에 쉽고 편리하지만 
      한번 정의된 필드에 서로 다른 타입의 데이터가 입력된다면 뒤에 입력딘 데이터의 색인 생성에 실패한다.
    - **매핑 정보를 설정할 때 고민할 점**
        - 문자열을 분석할 것인가?
        - `_source`에 어떤 필드를 정의할 것인가?
        - 날짜 필드를 가지는 필드는 무엇인가?
        - 매핑에 정의되지 않고 유입되는 필드는 어떻게 처리할 것인가?

- 매핑 인덱스 만들기
    - `실제 검색 대상이 되는 필드`는 분석 가능하도록 `text` 타입으로 정의
    - `해당 정보를 그대로 조회`하기 위해 integer, keyword 타입으로 정의
    - 특정 필드에 내부적으로 또 다른 문서 구조를 갖도록 정의하여 `계층형 구조`로 설정이 가능

- 매핑 확인
    - 이미 만들어진 매핑을 확인하려면 엘라스틱 서치에서 제공하는 _mapping API 를 사용할 수 있다.
    ```shell
    GET {index 명}/_mapping
    ```

### 3.2 매핑 파라미터

- 색인할 필드의 데이터를 어떻게 저장할지에 대한 다양한 옵션을 제공
- `analyzer`
    - 해당 필드의 데이터를 형태소 분석하겠다는 의미의 파라미터
    - 색인과 검색 시 지정한 분석기로 형태소 분석을 수행
    - text 데이터 타입의 필드는 analyzer 매핑 파라미터를 기본적으로 사용
    - 별도로 분석기를 지정하지 않으면 Standard Analyzer 로 형태소 분석을 수행

- `normalizer`
    - `term query`에 `분석기를 사용`하기 위해서 사용
    ```text
    ex) keyword 데이터 타입의 경우 원문을 기준으로 문서가 색인되기 때문에 cafe, Cafe, Café는 서로 다른문서로 인식된다.
    하지만 해당 유형을 normalizer를 통해 분석기에 asciifolding과 같은 필터를 사용하면 같은 데이터로 인식되게 할 수 있다.
    ```

- `boost`
    - 필드에 가중치를 부여한다.
    - 가중치에 따른 유사도 점수(_score)가 달라지기 때문에 boost 설정 시 검색 결과의 노출 순서에 영향을 준다.
    - 만약 색인 시점에 boost 설정을 하게 된다면, 재색인하지 않는 이상 가중치 변경을 할 수 없기 떄문에 주의해서 사용 필요
    - 가급적이면 `검색 시점에만 사용`하는 것을 권장한다.
    > 최근 엘라스틱서치는 색인 시 boost 설정을 할 수 없도록 바뀌었다. [참고](https://stackoverflow.com/questions/45822066/index-time-field-level-boosting-in-lucene-6-6-0)

- `coerce`
    - 색인 시 자동 변호나을 허용할 지 여부를 설정하는 파라미터
    - 숫자 형태의 문자열이 integer 타입의 필드에 들어온다면 엘라스틱서치는 자동으로 형변환을 수행해서 정상적으로 처리
    - coerce 설정을 미사용으로 변경하는 경우 색인에 실패

- `copy_to`
    - 매핑 파라미터를 추가한 필드의 값을 지정한 필드로 복사
    - keyword 타입의 필드에 copy_to 매핑 파라미터를 사용해 다른 필드로 값을 복사하면 
      복사된 필드에서는 text 타입을 지정해 형태소 분석이 가능
    - 여러 개의 필드 데이터를 하나의 필드에 모아서 전체 검색 용도로 사용하여 `_all` 컬럼과 동일한 기능을 제공 가능

- `fielddata`
    - 엘라스틱 서치가 `힙 공간에 생성하는 메모리 캐시`
    - 반복적인 메모리 부족 현상과 잦은 GC로 현재는 거의 사용하지 않음
    - 최신 버전의 엘라스틱서치는 `doc_values` 라는 새로운 형태의 캐시를 제공
    - `text 타입의 필드를 제외`한 `모든 필드는 기본적`으로 `doc_values 캐시`를 사용
    - `fielddata`는 메모리 소모가 크기 때문에 기본적으로 **비활성화**되어 있다.
    - 그럼에도 `fielddata`를 사용해야 하는 경우
        - `text` 타입의 필드에서 집계나 정렬을 수행하는 경우 <br>
          (`text` 타입의 필드는 기본적으로 분석기에 의해 형태소 분석이 되기 떄문에 집계나 정렬 등의 기능을 수행할 수 없다.)
    - 사용방법
        ```shell
        PUT {index명}/_mapping/_doc
        {
          "properties" : {
            "{필드명}" : {
              "type" : "text",
              "fielddata" : true
            }
          }
        }
        ```
- `doc_values`
    - 엘라스틱서치에서 사용하는 기본 캐시
    - `text 타입을 제외`한 `모든 타입`에서 기본적으로 `doc_values 캐시`를 사용
    - 과거에는 캐시를 모두 메모리에 올려서 사용하였으나 현재는 `doc_values`를 사용함으로써 힙 사용에 대한 부담을 없애고, 
      운영체제의 파일시스템 캐시를 통해 디스크에 있는 데이터에 빠르게 접근할 수 있다.
    - **GC의 비용이 들지 않으면서 메모리 연산과 비슷한 성능을 보여준다.**
    - 필드를 정렬, 집계할 필요가 없고 스크립트에서 필드 값에 액세스할 필요가 없다면 디스크 공간을 절약하기 위해 `doc_values`를 비활성화 가능
    - 한 번 비활성화된 필드는 인덱스를 재색인 하지 않는 한 변경 불가

- `dynamic`
    - 매핑에 필드를 추가할 때 동적으로 생성할 지, 생성하지 않을지를 결정
    - 동적 생성 필드의 처리 방벙 세 가지

        |인자|설명|
        |:---|:---|
        |true|새로 추가되는 필드를 매핑에 추가|
        |false|새로 추가되는 필드를 무시,<br> 해당 필드는 색인되지 않아 검색할 수 없지만, `_source`(메타필드)에는 표시|
        |strict|새로운 필드가 감지되면 예외가 발생하고 문서 자체가 색인되지 않는다. <br/> 새로 유입되는 필드는 사용자가 매핑에 명시적으로 추가해야 한다.|

- `enabled`
    - 검색 결과에는 포함하지만, 색인은 하고 싶지 않은 경우에 대한 설정 (`메타 성격의 데이터`)
        ```text
        ex) 일반적인 게시판의 경우 제목과 요약 글만 색인, 날짜와 사용자 ID는 색인하지 않는 경우
        ```
    - 사용방법
        - enabled를 false로 설정 시 _source에는 검색이 되지만 색인은 하지 않는다.
- `format`
    - 날짜/시간을 문자열로 표시, 해당 데이터 타입으로 변경 시 미리 구성된 포맷을 사용할 수 있다.
    - 날짜/시간 데이터 타입의 날짜 형식

        |포맷|날짜 형식|비고|
        |:---|:---|:---|
        |basic_date|yyyyMMdd|년도/월/일|
        |basic_date_time|yyyyMMdd'T'HHmmss.SSSZ|년도/월/일|
        |basic_time|HHmmss.SSSZ|시/분/초/밀리초/Z|
        |date/<br/>strict_date|yyyy-MM-dd|년도/시/분|
        |date_hour_minute_second/<br/>strict_date_hour_minute_second|yyyy-MM-dd'T'HH:mm:ss.|년도/시/분/T/시/분/초|
        |date_hour_minute_second_millis/<br/>strict_date_hour_minute_second_millis|yyyy-MM-dd'T'HH:mm:ss.SSS|년도/시/분/T/시/분/초/밀리초|
        |date_time/<br/>strict_date_time|yyyy-MM-dd'T'HH:mm:ss.SSSZZ|년도/시/분/T/시/분/초/밀리초/ZZ|

- `ignore_above`
    - 필드에 저장되는 문자열이 지정한 크기를 넘어서면 빈 값으로 색인
    - 지정한 크기만큼만 색인 되는 것이 아니라 빈 값으로 저장되므로 주의

- `ignore_malformed`
    - 잘못된 데이터 타입을 색인하려고 하면 예외가 발생하고 해당 문서 전체가 색인되지 않는다.
    - 매핑 파라미터 사용시, 해당 필드만 무시하고 문서는 색인할 수 있다.

- `index`
    - 필드 값을 색인 여부를 결정
    - 기본 값은 true, false로 변경하면 해당 필드를 색인하지 않는다.

- `fields`
    - 다중 필드(multi_field)를 설정할 수 있는 옵션
    - 필드 안에 또 다른 필드의 정보를 추가할 수 있어 같은 string 값을 각각 다른 분석기로 처리하도록 설정할 수 있다.
        ```text
        ex) 기본 필드는 전문검색, 필드 안의 추가 필드는 집계용으로 사용 가능
        ```
        - 요청 API
        ```shell
        PUT {index명}
        {
          "mappings": {
            "_doc" : {
              "properties" : {
                // 전문검색
                "{필드명}": {
                  "type" : "text",
                  "fields": {
                    // 집계용 필드
                    "{추가필드명}" : {
                      "type" : "keyword"
                    }
                  }
                }
              }
            }
          }
        }
        ```

- `norms`
    - 문서의 `_score` 값 계산에 필요한 정규화 인수를 사용할지 여부를 설정
    - 기본 값은 true, `_score` 계산이 필요없거나 단순 필터링 용도로 사용하는 필드는 비활성화해서 디스크 공간을 절약할 수 있다.

- `null_value`
    - 색인 시 문서에 필드가 없거나 필드의 값이 `null`이면 색인 시 필드를 생성하지 않는다.
    - `null_value`를 설정할 경우 문서의 값이 `null` 이더라도 필드를 생성하고 그에 해당하는 값으로 저장한다.
    - 요청 API
        ```shell
        PUT {index명}/_mapping/_doc
        {
          "properties": {
            "{필드명}": {
              "type": "integer",
              "null_value": "0"
            }
          }
        }
        ```

- `position_increment_gap`
    - 배열 혈태의 데이터를 색인할 떄 검색의 정확도를 높이기 위해 제공하는 옵션
    - 필드 데이터 중 단어와 단어 사이의 간격을 허용할 지 여부를 설정
    - 검색 시 단어와 단어 사이의 간격을 기준으로 일치하는 문서를 찾는데 필요
    ```text
    {"Jone Abraham", "Lincon Smith"}
    "Abraham Lincon"으로 검색 시 검색이 가능
    ```

- `properties`
    - 오브젝트(object) 타입이나 중첩(nested) 타입의 스키마를 정의할 때 사용되는 옵션
    - 필드의 타입을 매핑
    - 오브젝트 필드 및 중첩 필드에는 `properties`라는 서브 필드가 있다.
    - `properties` 는 `object`나 `nested`를 포함한 모든 데이터 타입이 될 수 있다.

- `search_analyzer`
    - 일반적으로 색인과 검색 시 같은 분석기를 사용
    - 만약 다른 분석기를 사용하고 싶은 경우 `search_analyzer`를 설정해서 검색 시 사용할 분석기를 `별도로 지정`할 수 있다.

- `similarity`
    - 유사도 측정 알고리즘을 지정
    - 유사도 측정 방식을 기본 알고리즘인 BM25에서 다른 알고리즘으로 변경할 수 있다.

        |알고리즘|설명|
        |:---|:---|
        |BM25|Okapi BM25 알고리즘으로 엘라스틱서 치의 기본 유사도 측정 알고리즘|
        |classic|TF/IDF 알고리즘으로 문서 내 용어의 개수와 전체 용어의 개수를 이용해 유사도를 계산|
        |boolean|복잡한 수학적 모델을 사용하지 않고 단순히 boolean  연산으로 유사도를 측정 <br> score는 검색어 일치 여부에 따라 결정, 검색 결과의 일치 여부에 따라 쿼리의 가중치에 사용된 점수로만 유사도를 계산|

- `store`
    - 필드 값을 저장하여 검색 결과에 값을 포함하기 위한 매핑 파라미터
    - 기본적으로 엘라스틱서치에서는 _source에 색인된 문서가 저장되는데, store 매핑 파라미터를 사용하면 해당 필드를 자체적으로 저장할 수 있다.
    - 10개의 필드가 존재하고 해당 필드에 데이터를 매핑한 상태인 경우 `_source를 로드해서 해당 필드를 찾는 것 보다` **사용할 각 필드로만 로드해서 사용하는 편이 효율적**
    - `store` 파라미터는 디스크를 더 많이 사용

- `term_vector`
    - 분석된 용어의 정보를 포함할지 여부를 결정
    
        |인자|설명|
        |:---|:---|
        |`no`|`term_bector`를 저장하지 않는다.|
        |`yes`|필드와 용어만 저장한다.|
        |`with_positions`|용어, 용어의 시작과 끝 위치를 저장|
        |`with_offsets`|용어, 문자 오프셋을 저장|
        |`with_positions_offsets`|용어, 용어의 시작과 끝 위치, 문자 오프셋을 모두 저장|

### 3.3 매타 필드(Meta Fields)
- 메타 필드는 엘라스틱 서치에서 생성한 문서에서 제공하는 특별한 필드
- 메타 데이터를 저장하는 특수 목적의 필드로서 이를 이용하여 검색 시 문서를 다양한 형태로 제어하는 것이 가능

- `_index` 메타 필드
    - 문서가 속한 인덱스의 이름을 담고 있다.
    - 이를 이용하여 검색된 문서의 인덱스명을 알 수 있으며, 해당 인덱스에 몇 개의 문서가 있는지 확인 할 수 있다.
    - 집계 API 호출
        ```shell
        POST {index명}/_search
        {
          "size": 0,
          "aggs": {
            "indices": {
              "terms": {
                "field" : "_index"
                "size" : 10
              }
            }
          }
        }
        ```
    - 결과
        - `인덱스별` 카운트 정보 확인 가능
        ```shell
        {
          // 집계 결과
          "aggregations": {
            // 인덱스 별 집계 
            "indices" : {
              "doc_count_error_upper_bound": 0,
              "sum_other_doc_count": 0,
              "buckets": [
                "key": "{index명}",
                // 해당 인덱스의 집계 count 
                "doc_count": 20000
              ]
            }
          }
        }
        ```

- `_type` 메타 필드
    - 해당 문서가 속한 매핑의 타입 정보를 담고 있다.
    - 해당 인덱스 내부에서 타입별로 몇 개의 문서가 있는지 확인 가능
    - 집계 API 호출
        ```shell
        POST {index명}/_serach
        {
          "size": 0,
          // 집계 API 호출
          "aggs": {
            "indices": {
              "terms": {
                // 타입별 사이즈 조회
                "field": "_type",
                "size": 10
              }
            }
          }
        }
        ```
    - 결과
        - `타입 별` 카운트 정보 확인
        ```shell
        {
          "aggregations": {
            // 인덱스 별 집계 
            "indices" : {
              "doc_count_error_upper_bound": 0,
              "sum_other_doc_count": 0,
              "buckets": [
                "key": "_doc",
                // 타입별 카운트 정보 
                "doc_count": 20000
              ]
            }
          }
        }
        ```

- `_id` 메타 필드
    - 문서를 식별하는 유일한 키 값
    - 한 인덱스에서 색인된 문서마다 서로 다른 키 값을 갖는다.
    - `_id` 검색 API 호출
        ```shell
        POST {index명}/_search
        {
          "size": 0,
          "aggs": {
            "indices": {
              "terms": {
                // 검색 질의를 통해 키 값에 대응하는 모든 문서를 출력
                "field": "_id",
                "size": 10
              }
            }
          }
        }
        ```
    - 결과
        - id 별 카운트 정보 확인
        ```shell
        "aggregations": {
          // 인덱스 별 집계 
          "indices" : {
            "doc_count_error_upper_bound": 0,
            "sum_other_doc_count": 20000,
            "buckets": [
              {
                "key": "A0001",
                "doc_count": 1
              },
              {
                "key": "A0002",
                "doc_count": 1
              },
              // ...
            ]
          }
        }
        ```

- `_uid` 메타 필드
    - 특수한 목적의 식별키
    - `#` 태그를 사용해 `_type`과 `_id`값을 조합해 사용
    - `내부적으로만 사용되기 때문에 검색 시 조회되는 값은 아니다.`
    - `_uid` 메타 필드 조회 API
        ```shell
        POST {index명}/_search
        {
          "size": 0,
          "aggs": {
            "indices": {
              "terms": {
                "field": "_uid",
                "size": 10
              }
            }
          }
        }
        ```
    - 결과
        ```shell
        "aggregations": {
          "indices" : {
            "doc_count_error_upper_bound": 5,
            "sum_other_doc_count": 20000,
            "buckets": [
              {
                "key": "_doc#A0001",
                "doc_count": 1
              },
              {
                "key": "_doc#A0002",
                "doc_count": 1
              },
              // ...
            ]
          }
        }
        ```

- `_source` 메타 필드
    - 문서의 정보를 담고 있는 항목은 `_source`
    - 내부에는 색인 시 전달된 원본 JSON 문서의 본문이 저장되어 있다.
    - 일반적으로 원본 JSON 문서를 검색 결과로 표시할 때 사용
    - `_reindex` API나 스크립트를 사용해 해당 값을 계산할 때 해당 메타 핋드를 활용

    - 문서를 구분할 수 있는 필드를 기준으로 조회하여, 특정 필드를 재색인 처리
        - 재색인을 위한 인덱스 생성
        ```shell
        PUT /{재색인을위한_인덱스명}
        ```
        - 재색인할 인덱스가 생성 된 후 reIndex API를 이용해 재색인을 수행
            - 특정 필드에 접근할 표기법으로 필드에 접근
            ```shell
            POST /_reindex
            {
              "source": {
                "index": "{index명}",
                "query": {
                  "match": {
                    "{검색필드명}" : "{검색필드값}"
                  }
                }
              },
              "dest": {
                "index": "{새로생성한인덱스명}" 
              },
              "script": {
                // 재색인할 떄 스크립트로 재색인 할 필드에 단순한 작업을 할 수 있다.
                "source": "ctx._source.{재색인 할 필드명}"
              }
            }
            ```

- `_all` 메타 필드
    - 색인에 사용된 모든 필드의 정보를 가진 메타 필드
    - 모든 필드의 내용이 하나의 텍스트로 합쳐져서 제공
    - 특정 필드가 아닌 `문서 전체 필드에서 특정 키워드를 검색`하는 경우 `_all` 메타 필드를 사용
    - `_all` 메타 필드에는 색인된 필드의 모든 값이 합쳐져서 하나의 문자열이 생성되어 저장된다.
        - 이를 이용한 통합검색 시 유리
    - **ES 6.0 이상**부터는 **deprecated** 되어 필드 복사가 필요한 경우 `copy_to` 파라미터를 사용

- `_routing` 메타 필드
    - 특정 문서를 특정 샤드에 저장하기 위해 사용자가 지정하는 메타 필드
    - 기본적으로 색인을 하면 해당 문서는 다음 수식에 따라 문서 id를 이용해 문서가 색인될 샤드를 결정
    - 별도의 설정 없이 문서를 색인하면 문서는 샤드에 골고루 분산되어 저장
        ```text
        Hash (document_id) % num_of_shards
        ```

    - 특정 문서들을 하나의 샤드에 저장하고 싶은 경우 `_routing` 메타 필드를 사용
        - 색인 시 해당 문서들은 동일한 라우팅 ID를 지정
        - 검색 시 파라미터에 지정한 `_routing` 값이 샤드를 결정하는데 사용
        ```text
        Hash (_routing) % num_of_shards
        ```

    - 예시
        - 특정 routing에 문서를 색인
        ```shell
        PUT {인덱스명}/_doc/1?routing=ko
        {
          "name": "이름",
          "age": 35
        }
        ```
        - 색인된 문서의 정보를 확인
        ```shell
        POST {인덱스명}/_doc/_search?routing=ko
        {
          "hits": {
            "total": 3,
            "max_score": 1.0,
            "hits": [
              {
                "_index": "{검색 인덱스명}",
                "_type": "_doc",
                "_id": "1",
                "_score": 1.0,
                "_routing": "ko",
                "_source": {
                  "name": "이름",
                  "age": 35
                }
              }
            ]
          }
        }
        ```

### 3.4 필드 데이터 타입


### [3.5 엘라스틱 서치 분석기](/docs/book/3.5_엘라스틱서치_분석기.md)
### [3.6 Document API 이해하기](/docs/book/3.6_Document_API_이해하기.md)
